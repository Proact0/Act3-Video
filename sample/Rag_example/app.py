import streamlit as st
from langchain_community.llms import Ollama

st.set_page_config(page_title="LangGraph RAG Demo", page_icon="ğŸ¦™")

st.title("ğŸ¦™ LangGraph + Ollama Demo")

# Ollama ëª¨ë¸ ì´ˆê¸°í™” (mistral ì˜ˆì‹œ)
llm = Ollama(model="mistral")

# ì…ë ¥ì°½
query = st.text_input("Enter your question:")

if query:
    st.write("### Question:")
    st.write(query)

    try:
        response = llm.invoke(query)
        st.write("### Answer:")
        st.write(response)
    except Exception as e:
        st.error(f"Error: {e}")
